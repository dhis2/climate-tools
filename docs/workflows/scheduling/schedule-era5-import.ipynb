{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ce531c6",
   "metadata": {},
   "source": [
    "# Schedule data imports\n",
    "\n",
    "This guide explains how to set up automated, scheduled imports of climate data into DHIS2. We demonstrate how to do this using the [Import ERA5-Land Daily](https://climate-tools.dhis2.org/workflows/import-era5/import-era5-daily/) workflow, showing how to move from interactive notebook exploration to production-ready scheduled imports. But the same approach can be used to setup a workflow for any other workflow or script. \n",
    "\n",
    "For running the notebook we are going to use [papermill](https://papermill.readthedocs.io/). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b846c2",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "Before starting, ensure you have:\n",
    "\n",
    "- Completed the [CDS API Authentication](../getting-data/climate-data-store/api-authentication.md) setup\n",
    "- A DHIS2 instance with a configured data element for daily ERA5-Land temperature (see [Prepare Metadata](./prepare-metadata.ipynb))\n",
    "- An installation of [Docker Desktop](https://www.docker.com/)\n",
    "    - Also make sure Docker Desktop is running at the time of running this notebook. \n",
    "- A basic familiarity with [the workflow for importing ERA5-Land data](../../workflows/import-era5/import-era5-daily.ipynb) which we are going to be automating. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38500b04",
   "metadata": {},
   "source": [
    "## 1) Gather the needed files\n",
    "\n",
    "For this tutorial, we are going to be using the provided [example](./example/) folder. Most of the files are already provided in the folder, and will be explained in more detail later. \n",
    "\n",
    "```bash\n",
    "    workflows/\n",
    "    └── scheduling/\n",
    "        └── example\n",
    "            ├── Dockerfile\n",
    "            ├── docker-compose.yml\n",
    "            ├── cronfile\n",
    "            ├── params.yaml\n",
    "            ├── requirements.txt  (copied from root folder later)\n",
    "            └── import-era5-daily.ipynb  (copied from workflows folder later)\n",
    "```\n",
    "\n",
    "Since we are also going to be needing the environment dependencies and ERA5-Land import notebook defined elsewhere in the toolkit, let's copy them over to our `example` folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81444c36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cronfile',\n",
       " 'docker-compose.yaml',\n",
       " 'Dockerfile',\n",
       " 'import-era5-daily.ipynb',\n",
       " 'params.yaml',\n",
       " 'requirements.txt']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "shutil.copy('../../import-era5/import-era5-daily.ipynb', './example/import-era5-daily.ipynb')\n",
    "shutil.copy('../../../../requirements.txt', './example/requirements.txt')\n",
    "os.listdir('./example')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa3d323",
   "metadata": {},
   "source": [
    "## 2) Make notebook configurable\n",
    "\n",
    "The [Import ERA5-Land Daily](https://climate-tools.dhis2.org/workflows/import-era5/import-era5-daily/) notebook hardcodes all input parameters, including sensitive settings like DHIS2 instance, username, and password. For automation, credentials and settings should be externalized rather than hardcoded in scripts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb08652",
   "metadata": {},
   "source": [
    "### Tag the parameters cell\n",
    "\n",
    "Since we are using [papermill](https://papermill.readthedocs.io/) to run the notebook, we first need to tell papermill where the parameters are defined. [As described here](https://papermill.readthedocs.io/en/latest/usage-parameterize.html#designate-parameters-for-a-cell), this is done by adding a `parameters` tag to the notebook cell containing the parameters. \n",
    "\n",
    "### Create the parameters yaml file\n",
    "\n",
    "Papermill can [read parameters from a yaml file](https://papermill.readthedocs.io/en/latest/usage-execute.html#using-a-parameters-file). This yaml file is used to define parameters that will override those in the notebook. Variable names should match those used in the notebook (from the cell tagged in the previous step). \n",
    "\n",
    "For this tutorial we have already created this [params.yaml](./example/params.yaml) file. We set the parameters so that the notebook imports temperature data instead of the default precipitation, and only for a single month for demonstration purposes. \n",
    "\n",
    "You can modify the parameters used by changing the contents of [params.yaml](./example/params.yaml)\n",
    "\n",
    "This approach allows:\n",
    "\n",
    "- **Security** - credentials stay out of version control\n",
    "- **Flexibility** - different settings for different import schedules\n",
    "- **Docker compatibility** - containers can load the parameters using the `--parameters_file` flag\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5891cc3e",
   "metadata": {},
   "source": [
    "## 3) Test the configured import notebook (NOT SURE IF THIS SHOULD BE DONE...)\n",
    "\n",
    "To test that the notebook can be run using the custom configuration, run this in your terminal:\n",
    "\n",
    "```bash\n",
    "    papermill example/import-era5-daily.ipynb ../../data/local/import-era5-daily-temperature-output.ipynb -f example/params.yaml --kernel climate-tools\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c6bcda9",
   "metadata": {},
   "source": [
    "Papermill will then copy the original notebook to the provided path (`../data/local/import-era5-daily-temperature-output.ipynb`), inject the parameters from `params.yaml`, and run the notebook. This means that after completion, you can open the notebook to see the results of the run and also what errors may have occured. \n",
    "\n",
    "Note that you won't see any output until the notebook hsa completed. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9296ca92",
   "metadata": {},
   "source": [
    "## 4) Schedule with Docker and cron\n",
    "\n",
    "For production use, we run imports automatically on a schedule using Docker and Cron schedules.\n",
    "\n",
    "For this step let's step into the `example` folder. Write this in your terminal:\n",
    "\n",
    "```bash\n",
    "    cd example\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f9bb4a",
   "metadata": {},
   "source": [
    "### Define the Docker image\n",
    "\n",
    "Defining a Docker image is needed to define the virtual operating system with needed tools such as `cron` to run schedules, the code and script files to import the data, and install the packages and environment needed to run them. We include an example [Dockerfile](./Dockerfile) that has what we will use for this tutorial. Its contents look like this:\n",
    "\n",
    "```bash\n",
    "    UPDATE LATER...\n",
    "```\n",
    "\n",
    "Note that to avoid hardcoding the scripts and input parameters into the Docker image, we only copy over the requirements.txt file needed to build the environment. The other files will be linked in a later stage. \n",
    "\n",
    "The image will be built in a later step. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e733aa4",
   "metadata": {},
   "source": [
    "### Define the cronfile\n",
    "\n",
    "To define the scheduled imports, we create a [cronfile](./example/cronfile), looking something like this:\n",
    "\n",
    "```bash\n",
    "    UPDATE LATER...\n",
    "```\n",
    "\n",
    "What the above `cronfile` does:\n",
    "\n",
    "1. Creates a crontab entry for running `import-era5-daily.ipynb` using the `params.yaml` parameters.\n",
    "2. Forwards output to Docker logs for monitoring.\n",
    "3. Runs continuously, executing the import on schedule.\n",
    "\n",
    "This will be running inside the Docker container and use the container file paths, as defined in the next step. \n",
    "\n",
    "You can also add multiple schedules to the same `cronfile`, so that one schedule runs the notebook with the temperature parameters file, and another schedule with a precipitation parameters file, and so on. Just remember to use filenames that differentiate the parameter and output files for each of the import schedules. \n",
    "\n",
    "Cron expression examples:\n",
    "\n",
    "| Expression | Description |\n",
    "|------------|-------------|\n",
    "| `0 6 * * *` | Daily at 6:00 AM |\n",
    "| `0 1 * * *` | Daily at 1:00 AM |\n",
    "| `0 0 * * 0` | Weekly on Sunday at midnight |\n",
    "| `0 0 1 * *` | Monthly on the 1st |\n",
    "\n",
    "Use [crontab.guru](https://crontab.guru/) to build expressions.\n",
    "\n",
    "**Important Gotcha on Windows**: If you are working with the `cronfile` on Windows, make sure you are saving it with LF line endings rather than the Windows CRLF, or Cron will complain. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee916c5",
   "metadata": {},
   "source": [
    "### Create a docker-compose file\n",
    "\n",
    "Create a docker compose file which will take the Docker image that we built, and run the `crontab` command on the [cronfile](./example/cronfile). We include an example [docker-compose.yaml](./example/docker-compose.yaml) file that can be used for this tutorial. It should look like this:\n",
    "\n",
    "```bash\n",
    "    UPDATE LATER...\n",
    "```\n",
    "\n",
    "Things to note:\n",
    "\n",
    "- The line `.:/app` is important and means that the `/app` folder Docker container will automatically be synced with the contents of the current folder (`.`). This way, any changes to the notebook, the parameters, and the cronfile scheduled runs, will not require you to `docker build` the Docker image again. \n",
    "- The line `~/.cdsapirc:/root/.cdsapirc:ro` makes your local CDS API key accessible in the Docker container `root` user folder. If you later change the Docker user then you have to update this to the correct user folder. This line is only needed for this particular workflow, because we are accessing data from the Climate Data Store (CDS). Other workflows may require other forms of authentication. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014f4111",
   "metadata": {},
   "source": [
    "### Build and run the scheduler with docker compose\n",
    "\n",
    "Starting the docker compose file will build the image (only the first time) and start the cron scheduler:\n",
    "\n",
    "```bash\n",
    "    docker compose up --detach --build\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a558fb95",
   "metadata": {},
   "source": [
    "To check that the docker container started successfully and is running:\n",
    "\n",
    "```bash\n",
    "    docker ps\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51294056",
   "metadata": {},
   "source": [
    "To listen in on the docker and cron logs:\n",
    "\n",
    "```bash\n",
    "    docker logs -f climate-scheduler\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a6efa1",
   "metadata": {},
   "source": [
    "Now the ERA5-Land imports should repeat at regular intervals as specified in the `cronfile`, for as long as the docker container `climate-scheduler` is running. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89aa722b",
   "metadata": {},
   "source": [
    "### Making changes to the notebook, parameters, or schedules\n",
    "\n",
    "If you make any changes to any of the files, you simply have to restart the docker container in order to restart `cron` and for the changes to take effect:\n",
    "\n",
    "```bash\n",
    "    docker compose down\n",
    "    docker compose up --detach --build\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc33e97",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "climate-tools-new",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
