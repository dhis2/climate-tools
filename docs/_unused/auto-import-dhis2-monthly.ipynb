{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: Automated imports using dhis2-python-client\n",
    "short_title: Automated imports\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NOTE: THIS NOTEBOOK IS OLD, AND WE PROBABLY WILL NOT SUPPORT MONTHLY ERA5 DATA ANYMORE, SINCE IT'S ALL AVERAGED\n",
    "\n",
    "If you have read through the tutorials up to this point, you should know all the steps needed to: \n",
    "\n",
    "- [Get organisation units](../org-units/intro.md)\n",
    "- [Download data](../getting-data/intro.md)\n",
    "- [Aggregate data](../aggregation/intro.md)\n",
    "- [Basic import into DHIS2](../import-data/using-python-client.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By putting all these steps together we can have a single script that can be rerun at regular intervals, to make sure that DHIS2 is continuously updated with the latest climate data. We will demonstrate how to do so in this notebook, with a focus on ERA5-Land data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to DHIS2\n",
    "\n",
    "First, we connect the python-client to the DHIS2 instance we want to import into. In this case we use one of the public access DHIS2 instances that is continuously reset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶ Current DHIS2 version: 2.42.3.1\n"
     ]
    }
   ],
   "source": [
    "from dhis2_client import DHIS2Client\n",
    "from dhis2_client.settings import ClientSettings\n",
    "\n",
    "# Client configuration\n",
    "cfg = ClientSettings(\n",
    "  base_url=\"https://play.im.dhis2.org/stable-2-42-3-1\",\n",
    "  username=\"admin\",\n",
    "  password=\"district\")\n",
    "\n",
    "client = DHIS2Client(settings=cfg)\n",
    "info = client.get_system_info()\n",
    "\n",
    "# Check if everything is working.\n",
    "# You should see your current DHIS2 version info.\n",
    "print(\"▶ Current DHIS2 version:\", info[\"version\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create DHIS2 data elements\n",
    "\n",
    "We also need to create the data elements for importing data into. If you haven't already created your data elements manually, you can follow the steps below to create the data element using the `python-dhis2-client`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, create the temperature data element: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data element creation status: OK and UID: QaUd7uG0pkV\n"
     ]
    }
   ],
   "source": [
    "data_element = {\n",
    "    \"name\": \"2m Temperature - Monthly (ERA5)\",\n",
    "    \"shortName\": \"Temperature - Monthly (ERA5)\",\n",
    "    \"valueType\": \"NUMBER\",\n",
    "    \"aggregationType\": \"AVERAGE\",\n",
    "    \"domainType\": \"AGGREGATE\"\n",
    "}\n",
    "temperature_created = client.create_data_element(data_element)\n",
    "print(f\"Data element creation status: {temperature_created['status']} and UID: {temperature_created['response']['uid']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, create the total precipitation data element: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data element creation status: OK and UID: fnUWyFEJPd2\n"
     ]
    }
   ],
   "source": [
    "data_element = {\n",
    "    \"name\": \"Total precipitation - Monthly (ERA5)\",\n",
    "    \"shortName\": \"Total precipitation - Monthly (ERA5)\",\n",
    "    \"valueType\": \"NUMBER\",\n",
    "    \"aggregationType\": \"SUM\",\n",
    "    \"domainType\": \"AGGREGATE\"\n",
    "}\n",
    "precipitation_created = client.create_data_element(data_element)\n",
    "print(f\"Data element creation status: {precipitation_created['status']} and UID: {precipitation_created['response']['uid']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we plan to import daily data values, we also create and assign our data element to a new dataset for climate variables with `Monthly` period type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data set creation status: OK and UID: UWekHet1YAf\n"
     ]
    }
   ],
   "source": [
    "data_set = {\n",
    "    \"name\": \"Monthly climate data\", \n",
    "    \"shortName\": \"Monthly climate data\",\n",
    "    \"periodType\": \"Monthly\",\n",
    "    \"dataSetElements\": [\n",
    "        {\n",
    "            \"dataElement\": {\"id\": temperature_created['response']['uid']},\n",
    "        },\n",
    "        {\n",
    "            \"dataElement\": {\"id\": precipitation_created['response']['uid']}\n",
    "        },\n",
    "    ]\n",
    "}\n",
    "\n",
    "data_set_created = client.create_data_set(data_set)\n",
    "print(f\"Data set creation status: {data_set_created['status']} and UID: {data_set_created['response']['uid']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the DHIS2 organisation units\n",
    "\n",
    "In order to download and aggregate the data to our DHIS2 organisation units, we also use the python-client to get the level 2 organisation units from our DHIS2 instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skipping field groups: unsupported OGR type: 5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>code</th>\n",
       "      <th>name</th>\n",
       "      <th>level</th>\n",
       "      <th>parent</th>\n",
       "      <th>parentGraph</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>O6uvpzGd5pu</td>\n",
       "      <td>OU_264</td>\n",
       "      <td>Bo</td>\n",
       "      <td>2</td>\n",
       "      <td>ImspTQPwCqd</td>\n",
       "      <td>ImspTQPwCqd</td>\n",
       "      <td>POLYGON ((-11.5914 8.4875, -11.5906 8.4769, -1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fdc6uOvgoji</td>\n",
       "      <td>OU_193190</td>\n",
       "      <td>Bombali</td>\n",
       "      <td>2</td>\n",
       "      <td>ImspTQPwCqd</td>\n",
       "      <td>ImspTQPwCqd</td>\n",
       "      <td>POLYGON ((-11.8091 9.2032, -11.8102 9.1944, -1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lc3eMKXaEfw</td>\n",
       "      <td>OU_197385</td>\n",
       "      <td>Bonthe</td>\n",
       "      <td>2</td>\n",
       "      <td>ImspTQPwCqd</td>\n",
       "      <td>ImspTQPwCqd</td>\n",
       "      <td>MULTIPOLYGON (((-12.5568 7.3832, -12.5574 7.38...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>jUb8gELQApl</td>\n",
       "      <td>OU_204856</td>\n",
       "      <td>Kailahun</td>\n",
       "      <td>2</td>\n",
       "      <td>ImspTQPwCqd</td>\n",
       "      <td>ImspTQPwCqd</td>\n",
       "      <td>POLYGON ((-10.7972 7.5866, -10.8002 7.5878, -1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PMa2VCrupOd</td>\n",
       "      <td>OU_211212</td>\n",
       "      <td>Kambia</td>\n",
       "      <td>2</td>\n",
       "      <td>ImspTQPwCqd</td>\n",
       "      <td>ImspTQPwCqd</td>\n",
       "      <td>MULTIPOLYGON (((-13.1349 8.8471, -13.1343 8.84...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>kJq2mPyFEHo</td>\n",
       "      <td>OU_222616</td>\n",
       "      <td>Kenema</td>\n",
       "      <td>2</td>\n",
       "      <td>ImspTQPwCqd</td>\n",
       "      <td>ImspTQPwCqd</td>\n",
       "      <td>POLYGON ((-11.3596 8.5317, -11.3513 8.5234, -1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>qhqAxPSTUXp</td>\n",
       "      <td>OU_226213</td>\n",
       "      <td>Koinadugu</td>\n",
       "      <td>2</td>\n",
       "      <td>ImspTQPwCqd</td>\n",
       "      <td>ImspTQPwCqd</td>\n",
       "      <td>POLYGON ((-10.585 9.0434, -10.5877 9.0432, -10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Vth0fbpFcsO</td>\n",
       "      <td>OU_233310</td>\n",
       "      <td>Kono</td>\n",
       "      <td>2</td>\n",
       "      <td>ImspTQPwCqd</td>\n",
       "      <td>ImspTQPwCqd</td>\n",
       "      <td>POLYGON ((-10.585 9.0434, -10.5848 9.0432, -10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>jmIPBj66vD6</td>\n",
       "      <td>OU_246990</td>\n",
       "      <td>Moyamba</td>\n",
       "      <td>2</td>\n",
       "      <td>ImspTQPwCqd</td>\n",
       "      <td>ImspTQPwCqd</td>\n",
       "      <td>MULTIPOLYGON (((-12.6351 7.6613, -12.6346 7.66...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>TEQlaapDQoK</td>\n",
       "      <td>OU_254945</td>\n",
       "      <td>Port Loko</td>\n",
       "      <td>2</td>\n",
       "      <td>ImspTQPwCqd</td>\n",
       "      <td>ImspTQPwCqd</td>\n",
       "      <td>MULTIPOLYGON (((-13.119 8.4718, -13.1174 8.470...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>bL4ooGhyHRQ</td>\n",
       "      <td>OU_260377</td>\n",
       "      <td>Pujehun</td>\n",
       "      <td>2</td>\n",
       "      <td>ImspTQPwCqd</td>\n",
       "      <td>ImspTQPwCqd</td>\n",
       "      <td>MULTIPOLYGON (((-11.5346 6.944, -11.5338 6.943...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>eIQbndfxQMb</td>\n",
       "      <td>OU_268149</td>\n",
       "      <td>Tonkolili</td>\n",
       "      <td>2</td>\n",
       "      <td>ImspTQPwCqd</td>\n",
       "      <td>ImspTQPwCqd</td>\n",
       "      <td>POLYGON ((-11.3546 8.6455, -11.357 8.6345, -11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>at6UHUQatSo</td>\n",
       "      <td>OU_278310</td>\n",
       "      <td>Western Area</td>\n",
       "      <td>2</td>\n",
       "      <td>ImspTQPwCqd</td>\n",
       "      <td>ImspTQPwCqd</td>\n",
       "      <td>MULTIPOLYGON (((-13.2435 8.1007, -13.2429 8.10...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id       code          name level       parent  parentGraph  \\\n",
       "0   O6uvpzGd5pu     OU_264            Bo     2  ImspTQPwCqd  ImspTQPwCqd   \n",
       "1   fdc6uOvgoji  OU_193190       Bombali     2  ImspTQPwCqd  ImspTQPwCqd   \n",
       "2   lc3eMKXaEfw  OU_197385        Bonthe     2  ImspTQPwCqd  ImspTQPwCqd   \n",
       "3   jUb8gELQApl  OU_204856      Kailahun     2  ImspTQPwCqd  ImspTQPwCqd   \n",
       "4   PMa2VCrupOd  OU_211212        Kambia     2  ImspTQPwCqd  ImspTQPwCqd   \n",
       "5   kJq2mPyFEHo  OU_222616        Kenema     2  ImspTQPwCqd  ImspTQPwCqd   \n",
       "6   qhqAxPSTUXp  OU_226213     Koinadugu     2  ImspTQPwCqd  ImspTQPwCqd   \n",
       "7   Vth0fbpFcsO  OU_233310          Kono     2  ImspTQPwCqd  ImspTQPwCqd   \n",
       "8   jmIPBj66vD6  OU_246990       Moyamba     2  ImspTQPwCqd  ImspTQPwCqd   \n",
       "9   TEQlaapDQoK  OU_254945     Port Loko     2  ImspTQPwCqd  ImspTQPwCqd   \n",
       "10  bL4ooGhyHRQ  OU_260377       Pujehun     2  ImspTQPwCqd  ImspTQPwCqd   \n",
       "11  eIQbndfxQMb  OU_268149     Tonkolili     2  ImspTQPwCqd  ImspTQPwCqd   \n",
       "12  at6UHUQatSo  OU_278310  Western Area     2  ImspTQPwCqd  ImspTQPwCqd   \n",
       "\n",
       "                                             geometry  \n",
       "0   POLYGON ((-11.5914 8.4875, -11.5906 8.4769, -1...  \n",
       "1   POLYGON ((-11.8091 9.2032, -11.8102 9.1944, -1...  \n",
       "2   MULTIPOLYGON (((-12.5568 7.3832, -12.5574 7.38...  \n",
       "3   POLYGON ((-10.7972 7.5866, -10.8002 7.5878, -1...  \n",
       "4   MULTIPOLYGON (((-13.1349 8.8471, -13.1343 8.84...  \n",
       "5   POLYGON ((-11.3596 8.5317, -11.3513 8.5234, -1...  \n",
       "6   POLYGON ((-10.585 9.0434, -10.5877 9.0432, -10...  \n",
       "7   POLYGON ((-10.585 9.0434, -10.5848 9.0432, -10...  \n",
       "8   MULTIPOLYGON (((-12.6351 7.6613, -12.6346 7.66...  \n",
       "9   MULTIPOLYGON (((-13.119 8.4718, -13.1174 8.470...  \n",
       "10  MULTIPOLYGON (((-11.5346 6.944, -11.5338 6.943...  \n",
       "11  POLYGON ((-11.3546 8.6455, -11.357 8.6345, -11...  \n",
       "12  MULTIPOLYGON (((-13.2435 8.1007, -13.2429 8.10...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Get org units GeoJSON from DHIS2\n",
    "level = 2\n",
    "org_units_geojson = client.get_org_units_geojson(level=level)\n",
    "\n",
    "# Convert GeoJSON to geopandas\n",
    "import geopandas as gpd\n",
    "import json\n",
    "org_units = gpd.read_file(json.dumps(org_units_geojson))\n",
    "org_units"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check when the data was last imported\n",
    "\n",
    "Since we want to run this script on a regular interval, we want to avoid importing data that has already been imported. We therefore first want to check the last date for which data was imported for the data element we want to import into. This can be done using the convenience function `analytics_latest_period_for_level()` provided by the python-client."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's get the last imported period for temperature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'meta': {'dataElement': 'QaUd7uG0pkV',\n",
       "  'level': 2,\n",
       "  'periodType': 'MONTHLY',\n",
       "  'calendar': 'iso8601',\n",
       "  'years_checked': 31},\n",
       " 'existing': None,\n",
       " 'next': None}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temperature_id = 'QaUd7uG0pkV'\n",
    "latest_temperature_response = client.analytics_latest_period_for_level(de_uid=temperature_id, level=level)\n",
    "latest_temperature_response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then the same for precipitation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'meta': {'dataElement': 'fnUWyFEJPd2',\n",
       "  'level': 2,\n",
       "  'periodType': 'MONTHLY',\n",
       "  'calendar': 'iso8601',\n",
       "  'years_checked': 31},\n",
       " 'existing': None,\n",
       " 'next': None}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precipitation_id = 'fnUWyFEJPd2'\n",
    "latest_precipitation_response = client.analytics_latest_period_for_level(de_uid=precipitation_id, level=level)\n",
    "latest_precipitation_response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading and importing the data\n",
    "\n",
    "The code below shows a simple example that loops through a number of months, downloads the data if the data has not already been imported into DHIS2, aggregate the data, and finally imports into DHIS2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data...\n",
      "dhis2eo.data.utils - INFO - Loading from cache: C:\\Users\\karimba\\AppData\\Local\\Temp\\dhis2eo_data_cds_era5_land_monthly_get_c1416fb567.nc\n",
      "\n",
      "Temperature:\n",
      "Aggregating...\n",
      "               id valid_time  number expver        t2m\n",
      "0     O6uvpzGd5pu 2015-01-01       0   0001  26.251556\n",
      "1     O6uvpzGd5pu 2015-02-01       0   0001  26.378998\n",
      "2     O6uvpzGd5pu 2015-03-01       0   0001  27.337402\n",
      "3     O6uvpzGd5pu 2015-04-01       0   0001  26.650909\n",
      "4     O6uvpzGd5pu 2015-05-01       0   0001  25.501617\n",
      "...           ...        ...     ...    ...        ...\n",
      "1685  at6UHUQatSo 2025-06-01       0   0001  25.937988\n",
      "1686  at6UHUQatSo 2025-07-01       0   0001  24.726624\n",
      "1687  at6UHUQatSo 2025-08-01       0   0001  24.437531\n",
      "1688  at6UHUQatSo 2025-09-01       0   0001  24.818390\n",
      "1689  at6UHUQatSo 2025-10-01       0   0005  25.724060\n",
      "\n",
      "[1690 rows x 5 columns]\n",
      "Importing...\n",
      "Import results: {'imported': 0, 'updated': 0, 'ignored': 1690, 'deleted': 0}\n",
      "\n",
      "Precipitation:\n",
      "Aggregating...\n",
      "               id valid_time  number expver         tp\n",
      "0     O6uvpzGd5pu 2015-01-01       0   0001   0.622292\n",
      "1     O6uvpzGd5pu 2015-02-01       0   0001   2.083224\n",
      "2     O6uvpzGd5pu 2015-03-01       0   0001   1.240943\n",
      "3     O6uvpzGd5pu 2015-04-01       0   0001   4.442704\n",
      "4     O6uvpzGd5pu 2015-05-01       0   0001   9.364225\n",
      "...           ...        ...     ...    ...        ...\n",
      "1685  at6UHUQatSo 2025-06-01       0   0001  13.862083\n",
      "1686  at6UHUQatSo 2025-07-01       0   0001  30.147627\n",
      "1687  at6UHUQatSo 2025-08-01       0   0001  27.272455\n",
      "1688  at6UHUQatSo 2025-09-01       0   0001  27.226284\n",
      "1689  at6UHUQatSo 2025-10-01       0   0005   8.594176\n",
      "\n",
      "[1690 rows x 5 columns]\n",
      "Importing...\n",
      "Import results: {'imported': 0, 'updated': 0, 'ignored': 1690, 'deleted': 0}\n"
     ]
    }
   ],
   "source": [
    "from dhis2eo import utils\n",
    "from dhis2eo.data.cds import era5_land\n",
    "from dhis2eo.integrations.pandas import dataframe_to_dhis2_json\n",
    "from earthkit import transforms\n",
    "\n",
    "# define years and months to download\n",
    "years = list(range(2015, 2025+1))\n",
    "months = list(range(1, 12+1))\n",
    "\n",
    "# download the data\n",
    "print('Downloading data...')\n",
    "monthly_data = era5_land.monthly.get(years=years, months=months, bbox=org_units.total_bounds)\n",
    "\n",
    "# temperature\n",
    "print('')\n",
    "print('Temperature:')\n",
    "## aggregate\n",
    "print('Aggregating...')\n",
    "agg = transforms.spatial.reduce(monthly_data['t2m'], org_units, mask_dim='id', how='mean')\n",
    "agg_df = agg.to_dataframe().reset_index()\n",
    "agg_df['t2m'] -= 273.15\n",
    "print(agg_df)\n",
    "## import\n",
    "print('Importing...')\n",
    "payload = dataframe_to_dhis2_json(\n",
    "    df=agg_df,\n",
    "    org_unit_col='id',\n",
    "    period_col='valid_time',\n",
    "    value_col='t2m',\n",
    "    data_element_id=temperature_id,\n",
    ")\n",
    "#res = client.post(\"/api/dataValueSets\", json=payload, params={\"dryRun\": \"true\"}) #.post_data_value_set(temp_payload)\n",
    "res = client.post_data_value_set(payload)\n",
    "print(f'Import results: {res['response']['importCount']}')\n",
    "\n",
    "# precipitation\n",
    "print('')\n",
    "print('Precipitation:')\n",
    "## aggregate\n",
    "print('Aggregating...')\n",
    "agg = transforms.spatial.reduce(monthly_data['tp'], org_units, mask_dim='id', how='mean')\n",
    "agg_df = agg.to_dataframe().reset_index()\n",
    "agg_df['tp'] *= 1000\n",
    "print(agg_df)\n",
    "## import\n",
    "print('Importing...')\n",
    "payload = dataframe_to_dhis2_json(\n",
    "    df=agg_df,\n",
    "    org_unit_col='id',\n",
    "    period_col='valid_time',\n",
    "    value_col='tp',\n",
    "    data_element_id=precipitation_id,\n",
    ")\n",
    "#res = client.post(\"/api/dataValueSets\", json=payload, params={\"dryRun\": \"true\"}) \n",
    "res = client.post_data_value_set(payload)\n",
    "print(f'Import results: {res['response']['importCount']}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify that the data was imported\n",
    "\n",
    "To verify that the data was imported, let's check again the last imported periods. \n",
    "\n",
    "Let's look specifically at temperature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'meta': {'dataElement': 'QaUd7uG0pkV',\n",
       "  'level': 2,\n",
       "  'periodType': 'MONTHLY',\n",
       "  'calendar': 'iso8601',\n",
       "  'years_checked': 1},\n",
       " 'existing': {'id': '20251001',\n",
       "  'startDate': '2025-10-01',\n",
       "  'endDate': '2025-10-01'},\n",
       " 'next': {'id': '20251002',\n",
       "  'startDate': '2025-10-02',\n",
       "  'endDate': '2025-10-02'}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# STILL EXPLORING\n",
    "client.analytics_latest_period_for_level(de_uid=temperature_id, level=level)\n",
    "#data_set_id = 'QVIFXY13UDE'\n",
    "#client.get_data_value_set({\n",
    "#    'dataSet': data_set_id, \n",
    "#    'dataElement': temperature_id,\n",
    "#    'orgUnit': 'O6uvpzGd5pu',\n",
    "#    'period': '202509'\n",
    "#})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "climate-tools-new",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
